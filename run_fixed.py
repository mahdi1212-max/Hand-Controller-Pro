"""
ÙØ§ÛŒÙ„ Ø§Ø¬Ø±Ø§ÛŒÛŒ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Hand Controller Pro v3.0
Fixed Runner for Hand Controller Pro v3.0
"""

import sys
import os
import cv2
import mediapipe as mp
import time
import numpy as np
import pyautogui
import math
import threading
import json
from ctypes import cast, POINTER
from comtypes import CLSCTX_ALL
from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume
import customtkinter as ctk
from PIL import Image, ImageTk

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø³ÛŒØ± ÙØ¹Ù„ÛŒ Ø¨Ù‡ sys.path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    from local_ai_controller import LocalAIController
    AI_AVAILABLE = True
except ImportError:
    AI_AVAILABLE = False
    print("Ú©Ù†ØªØ±Ù„Ø± AI Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.........................")

class FixedHandController:
    def __init__(self):
        """Ú©Ù†ØªØ±Ù„Ø± Ø¯Ø³Øª Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡"""
        print("ğŸš€ Ø¯Ø± Ø­Ø§Ù„ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Hand Controller Pro v3.0...")
        
        # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡
        self.setup_camera()
        self.setup_mediapipe()
        self.setup_audio()
        self.setup_ai_controller()
        
        # Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ú©Ù†ØªØ±Ù„
        self.state = "CALIBRATING"
        self.last_state_change_time = 0
        self.calibration_step = 0
        self.calibration_timer = time.time()
        
        # Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø§ÙˆØ³
        self.smoothening = 5
        self.plocX, self.plocY = 0, 0
        self.is_dragging = False
        self.click_cooldown = 0
        self.CLICK_DELAY = 0.25
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ†
        self.calibrated_thresholds = {
            "CLICK_DISTANCE": 35,
            "VOL_MIN_DIST": 30,
            "VOL_MAX_DIST": 200,
        }
        
        # Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ
        self.root = None
        self.setup_gui()
        
        # Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ ØªØ¬Ø§Ø±ÛŒ
        self.session_data = {
            "start_time": time.time(),
            "commands_executed": 0,
            "gestures_detected": 0,
            "errors": 0
        }
        
        # Ú©ÛŒØ¨ÙˆØ±Ø¯ Ù…Ø¬Ø§Ø²ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
        self.setup_virtual_keyboard()
        
        # Ù‚Ø§Ø¨Ù„ÛŒØªâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
        self.gesture_history = []
        self.performance_metrics = {}
        self.previous_hand_landmarks = {'left': None, 'right': None} # Ø¨Ø±Ø§ÛŒ Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ú˜Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒÚ†ÛŒØ¯Ù‡â€ŒØªØ±
        
        print("âœ… Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ú©Ø§Ù…Ù„ Ø´Ø¯!")
        
    def setup_camera(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¯ÙˆØ±Ø¨ÛŒÙ†"""
        self.wCam, self.hCam = 1280, 720
        # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† Ø¯ÙˆØ±Ø¨ÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
        for camera_id in [ 1, 2]:
            self.cap = cv2.VideoCapture(camera_id)
            if self.cap.isOpened():
                print(f"âœ… Ø¯ÙˆØ±Ø¨ÛŒÙ† {camera_id} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø² Ø´Ø¯")
                break
        else:
            print("âŒ Ù‡ÛŒÚ† Ø¯ÙˆØ±Ø¨ÛŒÙ†ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯!")
            self.cap = cv2.VideoCapture(0)  # fallback Ø¨Ù‡ Ø¯ÙˆØ±Ø¨ÛŒÙ† Ù¾ÛŒØ´â€ŒÙØ±Ø¶
            
        self.cap.set(3, self.wCam)
        self.cap.set(4, self.hCam)
        self.frame_reduction = 100
        
    def setup_mediapipe(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ MediaPipe"""
        self.mp_hands = mp.solutions.hands
        self.hands = self.mp_hands.Hands(
            static_image_mode=False,
            max_num_hands=2, 
            min_detection_confidence=0.7,  # Ú©Ø§Ù‡Ø´ Ø­Ø³Ø§Ø³ÛŒØª Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø¨Ù‡ØªØ±
            min_tracking_confidence=0.5
        )
        self.mp_drawing = mp.solutions.drawing_utils
        print("âœ… MediaPipe Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯")
        
    def setup_audio(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ú©Ù†ØªØ±Ù„ ØµØ¯Ø§"""
        try:
            devices = AudioUtilities.GetSpeakers()
            interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)
            self.volume = cast(interface, POINTER(IAudioEndpointVolume))
            volRange = self.volume.GetVolumeRange()
            self.minVol, self.maxVol = volRange[0], volRange[1]
            self.volume_control_enabled = True
            print("âœ… Ú©Ù†ØªØ±Ù„ ØµØ¯Ø§ ÙØ¹Ø§Ù„ Ø´Ø¯")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ú©Ù†ØªØ±Ù„ ØµØ¯Ø§: {e}")
            self.volume_control_enabled = False
            
    def setup_ai_controller(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ú©Ù†ØªØ±Ù„Ø± AI"""
        if AI_AVAILABLE:
            try:
                self.ai_controller = LocalAIController()
                print("âœ… Ú©Ù†ØªØ±Ù„Ø± AI ÙØ¹Ø§Ù„ Ø´Ø¯")
            except Exception as e:
                print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ AI: {e}")
                self.ai_controller = None
        else:
            self.ai_controller = None
            print("âš ï¸ Ú©Ù†ØªØ±Ù„Ø± AI Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª")
        
    def setup_gui(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ"""
        ctk.set_appearance_mode("dark")
        ctk.set_default_color_theme("blue")
        
        self.root = ctk.CTk()
        self.root.title("Advanced Hand Controller Pro v3.0 - Fixed")
        self.root.geometry("400x600")
        
        # Ø§ÛŒØ¬Ø§Ø¯ ÙˆÛŒØ¬Øªâ€ŒÙ‡Ø§
        self.create_gui_widgets()
        
    def create_gui_widgets(self):
        """Ø§ÛŒØ¬Ø§Ø¯ ÙˆÛŒØ¬Øªâ€ŒÙ‡Ø§ÛŒ Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ"""
        # Ø¹Ù†ÙˆØ§Ù†
        title_label = ctk.CTkLabel(
            self.root, 
            text="Hand Controller Pro v3.0",
            font=ctk.CTkFont(size=24, weight="bold")
        )
        title_label.pack(pady=20)
        
        # ÙˆØ¶Ø¹ÛŒØª
        self.status_label = ctk.CTkLabel(
            self.root,
            text="Status: Ready",
            font=ctk.CTkFont(size=16)
        )
        self.status_label.pack(pady=10)
        
        # Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ú©Ù†ØªØ±Ù„
        self.start_button = ctk.CTkButton(
            self.root,
            text="Start Control",
            command=self.start_control,
            width=200,
            height=40
        )
        self.start_button.pack(pady=10)
        
        self.stop_button = ctk.CTkButton(
            self.root,
            text="Stop Control",
            command=self.stop_control,
            width=200,
            height=40,
            state="disabled"
        )
        self.stop_button.pack(pady=10)
        
        # Ø¯Ú©Ù…Ù‡ Ú©Ù†ØªØ±Ù„ ØµÙˆØªÛŒ
        if self.ai_controller:
            self.voice_button = ctk.CTkButton(
                self.root,
                text="Start Voice Control",
                command=self.toggle_voice_control,
                width=200,
                height=40
            )
            self.voice_button.pack(pady=10)
        
        # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø±
        self.stats_frame = ctk.CTkFrame(self.root)
        self.stats_frame.pack(pady=20, padx=20, fill="both", expand=True)
        
        self.stats_label = ctk.CTkLabel(
            self.stats_frame,
            text="Statistics:\nCommands: 0\nGestures: 0\nErrors: 0",
            font=ctk.CTkFont(size=14)
        )
        self.stats_label.pack(pady=10)
        
    def setup_virtual_keyboard(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ú©ÛŒØ¨ÙˆØ±Ø¯ Ù…Ø¬Ø§Ø²ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
        class AdvancedButton:
            def __init__(self, pos, text, size=[80, 80], color=(100, 0, 100)):
                self.pos = pos
                self.size = size
                self.text = text
                self.color = color
                self.is_pressed = False
                
        # Ú©ÛŒØ¨ÙˆØ±Ø¯ ÙØ§Ø±Ø³ÛŒ Ùˆ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
        self.keys = [
            ["Q", "W", "E", "R", "T", "Y", "U", "I", "O", "P"],
            ["A", "S", "D", "F", "G", "H", "J", "K", "L", ";"],
            ["Z", "X", "C", "V", "B", "N", "M", ",", ".", "/"],
            ["1", "2", "3", "4", "5", "6", "7", "8", "9", "0"]
        ]
        
        self.buttonList = []
        for i in range(len(self.keys)):
            for j, key in enumerate(self.keys[i]):
                self.buttonList.append(AdvancedButton([100 * j + 50, 100 * i + 150], key))
        
        # Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆÛŒÚ˜Ù‡
        self.buttonList.append(AdvancedButton([50, 450], "Space", [400, 80], (0, 100, 100)))
        self.buttonList.append(AdvancedButton([460, 450], "<-", [100, 80], (100, 100, 0)))
        self.buttonList.append(AdvancedButton([570, 450], "Enter", [100, 80], (0, 100, 0)))
        self.buttonList.append(AdvancedButton([680, 450], "Exit", [150, 80], (100, 0, 0)))
        
        self.final_text = ""
        
    def detect_advanced_gestures(self, image, left_hand_landmarks, right_hand_landmarks):
        """ØªØ´Ø®ÛŒØµ Ú˜Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ (Ù…Ø§Ù†Ù†Ø¯ Ø§Ø³Ú©Ø±ÙˆÙ„ØŒ Ø²ÙˆÙ…) Ùˆ Ø§Ø¬Ø±Ø§ÛŒ Ø¯Ø³ØªÙˆØ±Ø§Øª Ù…Ø±Ø¨ÙˆØ·Ù‡"""
        if left_hand_landmarks and right_hand_landmarks:
            # Ú˜Ø³Øª Ø¨Ø§ Ø¯Ùˆ Ø¯Ø³Øª (Ù…Ø«Ù„Ø§Ù‹ Ø²ÙˆÙ…)
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø±Ú©Ø² Ù‡Ø± Ø¯Ø³Øª
            left_cx = int(sum([lm.x for lm in left_hand_landmarks.landmark]) / len(left_hand_landmarks.landmark) * self.wCam)
            left_cy = int(sum([lm.y for lm in left_hand_landmarks.landmark]) / len(left_hand_landmarks.landmark) * self.hCam)
            right_cx = int(sum([lm.x for lm in right_hand_landmarks.landmark]) / len(right_hand_landmarks.landmark) * self.wCam)
            right_cy = int(sum([lm.y for lm in right_hand_landmarks.landmark]) / len(right_hand_landmarks.landmark) * self.hCam)

            # Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙØ§ØµÙ„Ù‡ Ø¨ÛŒÙ† Ù…Ø±Ø§Ú©Ø² Ø¯Ùˆ Ø¯Ø³Øª
            current_hands_distance = math.hypot(right_cx - left_cx, right_cy - left_cy)

            if self.previous_hand_landmarks['left'] and self.previous_hand_landmarks['right']:
                prev_left_cx = int(sum([lm.x for lm in self.previous_hand_landmarks['left'].landmark]) / len(self.previous_hand_landmarks['left'].landmark) * self.wCam)
                prev_left_cy = int(sum([lm.y for lm in self.previous_hand_landmarks['left'].landmark]) / len(self.previous_hand_landmarks['left'].landmark) * self.hCam)
                prev_right_cx = int(sum([lm.x for lm in self.previous_hand_landmarks['right'].landmark]) / len(self.previous_hand_landmarks['right'].landmark) * self.wCam)
                prev_right_cy = int(sum([lm.y for lm in self.previous_hand_landmarks['right'].landmark]) / len(self.previous_hand_landmarks['right'].landmark) * self.hCam)

                prev_hands_distance = math.hypot(prev_right_cx - prev_left_cx, prev_right_cy - prev_left_cy)

                distance_diff = current_hands_distance - prev_hands_distance
                zoom_threshold = 15 # Ø­Ø¯Ø§Ù‚Ù„ ØªØºÛŒÛŒØ± ÙØ§ØµÙ„Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø²ÙˆÙ…

                if abs(distance_diff) > zoom_threshold:
                    if distance_diff > 0: # Ø¯Ø³Øªâ€ŒÙ‡Ø§ Ø§Ø² Ù‡Ù… Ø¯ÙˆØ± Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯: Ø²ÙˆÙ… Ø¨Ù‡ Ø¨ÛŒØ±ÙˆÙ†
                        pyautogui.hotkey('ctrl', '-')
                        self.draw_text_with_bg(image, "Zoom Out", (self.wCam // 2 - 100, 50), color=(0, 255, 255))
                        print("ğŸ” Ø²ÙˆÙ… Ø¨Ù‡ Ø¨ÛŒØ±ÙˆÙ†")
                    else: # Ø¯Ø³Øªâ€ŒÙ‡Ø§ Ø¨Ù‡ Ù‡Ù… Ù†Ø²Ø¯ÛŒÚ© Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯: Ø²ÙˆÙ… Ø¨Ù‡ Ø¯Ø§Ø®Ù„
                        pyautogui.hotkey('ctrl', '+')
                        self.draw_text_with_bg(image, "Zoom In", (self.wCam // 2 - 100, 50), color=(0, 255, 255))
                        print("ğŸ” Ø²ÙˆÙ… Ø¨Ù‡ Ø¯Ø§Ø®Ù„")
                    self.session_data["commands_executed"] += 1
                    self.last_state_change_time = time.time() # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªØºÛŒÛŒØ± Ø­Ø§Ù„Øª Ù†Ø§Ø®ÙˆØ§Ø³ØªÙ‡


        elif right_hand_landmarks:
            current_right_hand_data = self.get_finger_states(right_hand_landmarks, "right")
            current_right_fingers = current_right_hand_data["finger_states"]
            current_thumb_index_dist = current_right_hand_data["thumb_index_dist"]

            # Ú˜Ø³Øª Ø§Ø³Ú©Ø±ÙˆÙ„ Ø¨Ø§ Ø¯Ø³Øª Ø±Ø§Ø³Øª (Ø§Ù†Ú¯Ø´Øª Ø§Ø´Ø§Ø±Ù‡ Ùˆ Ù…ÛŒØ§Ù†ÛŒ Ø¨Ù‡ Ø³Ù…Øª Ø¨Ø§Ù„Ø§/Ù¾Ø§ÛŒÛŒÙ†)
            # ØªÙ†Ù‡Ø§ Ø§Ù†Ú¯Ø´Øª Ø§Ø´Ø§Ø±Ù‡ Ùˆ Ù…ÛŒØ§Ù†ÛŒ Ø¨Ø§Ø² Ø¨Ø§Ø´Ù†Ø¯ Ùˆ ÙØ§ØµÙ„Ù‡ Ø¨ÛŒÙ† Ø¢Ù†Ù‡Ø§ Ø«Ø§Ø¨Øª Ùˆ Ù†Ø²Ø¯ÛŒÚ© Ø¨Ø§Ø´Ø¯
            if current_right_fingers[1] == 1 and current_right_fingers[2] == 1 and sum(current_right_fingers) == 2:
                # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø±Ú©Øª Ø¹Ù…ÙˆØ¯ÛŒ Ø§Ù†Ú¯Ø´Øª Ø§Ø´Ø§Ø±Ù‡
                if self.previous_hand_landmarks['right']:
                    prev_index_tip_y = self.previous_hand_landmarks['right'].landmark[8].y * self.hCam
                    current_index_tip_y = right_hand_landmarks.landmark[8].y * self.hCam

                    delta_y = current_index_tip_y - prev_index_tip_y
                    scroll_threshold = 10 # Ø­Ø¯Ø§Ù‚Ù„ Ø­Ø±Ú©Øª Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø§Ø³Ú©Ø±ÙˆÙ„

                    if abs(delta_y) > scroll_threshold:
                        if delta_y < 0: # Ø­Ø±Ú©Øª Ø¨Ù‡ Ø¨Ø§Ù„Ø§
                            pyautogui.scroll(100)
                            self.draw_text_with_bg(image, "Scroll Up", (self.wCam - 200, 50), color=(0, 255, 0))
                            print("â¬†ï¸ Ø§Ø³Ú©Ø±ÙˆÙ„ Ø¨Ù‡ Ø¨Ø§Ù„Ø§")
                        else: # Ø­Ø±Ú©Øª Ø¨Ù‡ Ù¾Ø§ÛŒÛŒÙ†
                            pyautogui.scroll(-100)
                            self.draw_text_with_bg(image, "Scroll Down", (self.wCam - 200, 50), color=(0, 255, 0))
                            print("â¬‡ï¸ Ø§Ø³Ú©Ø±ÙˆÙ„ Ø¨Ù‡ Ù¾Ø§ÛŒÛŒÙ†")
                        self.session_data["commands_executed"] += 1
                        self.last_state_change_time = time.time() # Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªØºÛŒÛŒØ± Ø­Ø§Ù„Øª Ù†Ø§Ø®ÙˆØ§Ø³ØªÙ‡

            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ú˜Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± ØªÚ© Ø¯Ø³ØªÛŒ Ø±Ø§Ø³Øª Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§

        elif left_hand_landmarks:
            # Ú˜Ø³Øªâ€ŒÙ‡Ø§ÛŒ ØªÚ© Ø¯Ø³ØªÛŒ Ø¨Ø§ Ø¯Ø³Øª Ú†Ù¾ (ÙØ¹Ù„Ø§Ù‹ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ ØªØºÛŒÛŒØ± Ø­Ø§Ù„Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯)
            pass
        
    def get_finger_states(self, hand_landmarks, hand_type):
        """ØªØ´Ø®ÛŒØµ ÙˆØ¶Ø¹ÛŒØª Ø§Ù†Ú¯Ø´ØªØ§Ù† Ùˆ Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙÙˆØ§ØµÙ„ Ú©Ù„ÛŒØ¯ÛŒ Ø¨ÛŒÙ† Ø§Ù†Ú¯Ø´ØªØ§Ù†"""
        finger_tips = [4, 8, 12, 16, 20]
        states = []
        
        # Ø§Ù†Ú¯Ø´Øª Ø´Ø³Øª
        if hand_type.lower() == 'right':
            states.append(1 if hand_landmarks.landmark[finger_tips[0]].x > hand_landmarks.landmark[finger_tips[0] - 1].x else 0)
        else:
            states.append(1 if hand_landmarks.landmark[finger_tips[0]].x < hand_landmarks.landmark[finger_tips[0] - 1].x else 0)
        
        # 4 Ø§Ù†Ú¯Ø´Øª Ø¯ÛŒÚ¯Ø±
        for i in range(1, 5):
            states.append(1 if hand_landmarks.landmark[finger_tips[i]].y < hand_landmarks.landmark[finger_tips[i] - 2].y else 0)
            
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙÙˆØ§ØµÙ„ Ú©Ù„ÛŒØ¯ÛŒ
        thumb_tip = (hand_landmarks.landmark[finger_tips[0]].x * self.wCam, hand_landmarks.landmark[finger_tips[0]].y * self.hCam)
        index_tip = (hand_landmarks.landmark[finger_tips[1]].x * self.wCam, hand_landmarks.landmark[finger_tips[1]].y * self.hCam)
        middle_tip = (hand_landmarks.landmark[finger_tips[2]].x * self.wCam, hand_landmarks.landmark[finger_tips[2]].y * self.hCam)
        ring_tip = (hand_landmarks.landmark[finger_tips[3]].x * self.wCam, hand_landmarks.landmark[finger_tips[3]].y * self.hCam)
        pinky_tip = (hand_landmarks.landmark[finger_tips[4]].x * self.wCam, hand_landmarks.landmark[finger_tips[4]].y * self.hCam)

        thumb_index_dist = math.hypot(index_tip[0] - thumb_tip[0], index_tip[1] - thumb_tip[1])
        index_middle_dist = math.hypot(middle_tip[0] - index_tip[0], middle_tip[1] - index_tip[1])
        
        return {"finger_states": states, "thumb_index_dist": thumb_index_dist, "index_middle_dist": index_middle_dist}
        
    def draw_text_with_bg(self, image, text, position, font_scale=1, color=(255, 255, 255), thickness=2, bg_color=(0, 0, 0, 128)):
        """Ø±Ø³Ù… Ù…ØªÙ† Ø¨Ø§ Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡"""
        (text_width, text_height), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)
        top_left = (position[0] - 5, position[1] - text_height - 10)
        bottom_right = (position[0] + text_width + 5, position[1] + baseline)
        
        overlay = image.copy()
        cv2.rectangle(overlay, top_left, bottom_right, bg_color[:3], cv2.FILLED)
        alpha = bg_color[3] / 255.0 if len(bg_color) > 3 else 0.5
        cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0, image)
        
        cv2.putText(image, text, position, cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness, cv2.LINE_AA)
        
    def run_calibration(self, image, hand_landmarks):
        """Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ† Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
        if self.calibration_step == 0:
            self.draw_text_with_bg(image, "Step 1: Show OPEN HAND for 3 sec", (50, 50), bg_color=(200,0,0,150))
            if hand_landmarks:
                if time.time() - self.calibration_timer > 3:
                    tx, ty = hand_landmarks.landmark[4].x * self.wCam, hand_landmarks.landmark[4].y * self.hCam
                    ix, iy = hand_landmarks.landmark[8].x * self.wCam, hand_landmarks.landmark[8].y * self.hCam
                    self.calibrated_thresholds["VOL_MAX_DIST"] = max(150, math.hypot(ix - tx, iy - ty))
                    self.calibration_step = 1
                    self.calibration_timer = time.time()
                    print(f"âœ… Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ† MAX distance: {self.calibrated_thresholds['VOL_MAX_DIST']:.2f}")
            else:
                self.calibration_timer = time.time()
        
        elif self.calibration_step == 1:
            self.draw_text_with_bg(image, "Step 2: Bring Thumb & Index together for 3 sec", (50, 50), bg_color=(200,0,0,150))
            if hand_landmarks:
                if time.time() - self.calibration_timer > 3:
                    tx, ty = hand_landmarks.landmark[4].x * self.wCam, hand_landmarks.landmark[4].y * self.hCam
                    ix, iy = hand_landmarks.landmark[8].x * self.wCam, hand_landmarks.landmark[8].y * self.hCam
                    self.calibrated_thresholds["VOL_MIN_DIST"] = math.hypot(ix - tx, iy - ty) + 10
                    
                    ix_tip, iy_tip = hand_landmarks.landmark[8].x * self.wCam, hand_landmarks.landmark[8].y * self.hCam
                    mx_tip, my_tip = hand_landmarks.landmark[12].x * self.wCam, hand_landmarks.landmark[12].y * self.hCam
                    self.calibrated_thresholds["CLICK_DISTANCE"] = math.hypot(ix_tip-mx_tip, iy_tip-my_tip) + 15
                    
                    self.calibration_step = 2
                    print(f"âœ… Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ† MIN distance: {self.calibrated_thresholds['VOL_MIN_DIST']:.2f}")
                    print(f"âœ… Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ† CLICK distance: {self.calibrated_thresholds['CLICK_DISTANCE']:.2f}")
            else:
                self.calibration_timer = time.time()
                
        elif self.calibration_step == 2:
            self.draw_text_with_bg(image, "Calibration Complete!", (50, 50), color=(0, 255, 0), bg_color=(0,100,0,150))
            if time.time() - self.calibration_timer > 2:
                self.state = "IDLE"
                self.update_status("Ready")
                print("âœ… Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ† Ú©Ø§Ù…Ù„ Ø´Ø¯!")
                
    def run_mouse_control(self, image, hand_landmarks):
        """Ú©Ù†ØªØ±Ù„ Ù…Ø§ÙˆØ³ Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
        self.draw_text_with_bg(image, "MOUSE CONTROL", (10, 40), color=(0, 255, 255))
        cv2.rectangle(image, (self.frame_reduction, self.frame_reduction), 
                     (self.wCam - self.frame_reduction, self.hCam - self.frame_reduction), (0, 255, 255), 2)

        fingers = self.get_finger_states(hand_landmarks, "right")
        
        # Ø­Ø±Ú©Øª Ù…Ø§ÙˆØ³
        if fingers["finger_states"][1] == 1 and fingers["finger_states"][2] == 0:
            if self.is_dragging:
                pyautogui.mouseUp(button='left')
                self.is_dragging = False
            
            ix, iy = hand_landmarks.landmark[8].x * self.wCam, hand_landmarks.landmark[8].y * self.hCam
            
            screen_w, screen_h = pyautogui.size()
            x_mapped = np.interp(ix, (self.frame_reduction, self.wCam - self.frame_reduction), (0, screen_w))
            y_mapped = np.interp(iy, (self.frame_reduction, self.hCam - self.frame_reduction), (0, screen_h))
            
            clocX = self.plocX + (x_mapped - self.plocX) / self.smoothening
            clocY = self.plocY + (y_mapped - self.plocY) / self.smoothening
            
            pyautogui.moveTo(clocX, clocY)
            self.plocX, self.plocY = clocX, clocY
            self.session_data["gestures_detected"] += 1

        # Ú©Ù„ÛŒÚ© Ú†Ù¾
        if fingers["finger_states"][1] == 1 and fingers["finger_states"][2] == 1:
            ix, iy = hand_landmarks.landmark[8].x * self.wCam, hand_landmarks.landmark[8].y * self.hCam
            mx, my = hand_landmarks.landmark[12].x * self.wCam, hand_landmarks.landmark[12].y * self.hCam
            distance = math.hypot(mx - ix, my - iy)
            
            if distance < self.calibrated_thresholds["CLICK_DISTANCE"] and time.time() > self.click_cooldown:
                pyautogui.click()
                self.click_cooldown = time.time() + self.CLICK_DELAY
                self.session_data["commands_executed"] += 1
                print("ğŸ–±ï¸ Ú©Ù„ÛŒÚ© Ú†Ù¾ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")

        # Ú©Ù„ÛŒÚ© Ø±Ø§Ø³Øª
        if fingers["finger_states"][0] == 1 and fingers["finger_states"][1] == 1:
            tx, ty = hand_landmarks.landmark[4].x * self.wCam, hand_landmarks.landmark[4].y * self.hCam
            ix, iy = hand_landmarks.landmark[8].x * self.wCam, hand_landmarks.landmark[8].y * self.hCam
            distance = math.hypot(tx - ix, ty - iy)

            if distance < self.calibrated_thresholds["CLICK_DISTANCE"] and time.time() > self.click_cooldown:
                pyautogui.rightClick()
                self.click_cooldown = time.time() + self.CLICK_DELAY + 0.2
                self.session_data["commands_executed"] += 1
                print("ğŸ–±ï¸ Ú©Ù„ÛŒÚ© Ø±Ø§Ø³Øª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")

        # Drag and Drop
        if all(f == 0 for f in fingers["finger_states"]):
            if not self.is_dragging:
                pyautogui.mouseDown(button='left')
                self.is_dragging = True
        else:
            if self.is_dragging and not (fingers["finger_states"][1] == 1 and fingers["finger_states"][2] == 0):
                pyautogui.mouseUp(button='left')
                self.is_dragging = False
                
    def run_system_control(self, image, hand_landmarks):
        """Ú©Ù†ØªØ±Ù„ Ø³ÛŒØ³ØªÙ… Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
        self.draw_text_with_bg(image, "SYSTEM CONTROL", (10, 40), color=(0, 255, 0))
        if not self.volume_control_enabled:
            self.draw_text_with_bg(image, "Volume control disabled", (10, 80), color=(255, 0, 0))
            return

        tx, ty = hand_landmarks.landmark[4].x * self.wCam, hand_landmarks.landmark[4].y * self.hCam
        ix, iy = hand_landmarks.landmark[8].x * self.wCam, hand_landmarks.landmark[8].y * self.hCam
        
        cv2.circle(image, (int(tx), int(ty)), 10, (0, 255, 0), cv2.FILLED)
        cv2.circle(image, (int(ix), int(iy)), 10, (0, 255, 0), cv2.FILLED)
        cv2.line(image, (int(tx), int(ty)), (int(ix), int(iy)), (0, 255, 0), 3)

        length_vol = math.hypot(ix - tx, iy - ty)
        
        vol = np.interp(length_vol, [self.calibrated_thresholds["VOL_MIN_DIST"], self.calibrated_thresholds["VOL_MAX_DIST"]], [self.minVol, self.maxVol])
        vol_bar = np.interp(length_vol, [self.calibrated_thresholds["VOL_MIN_DIST"], self.calibrated_thresholds["VOL_MAX_DIST"]], [400, 150])
        vol_per = np.interp(length_vol, [self.calibrated_thresholds["VOL_MIN_DIST"], self.calibrated_thresholds["VOL_MAX_DIST"]], [0, 100])
        
        self.volume.SetMasterVolumeLevel(vol, None)
        
        cv2.rectangle(image, (50, 150), (85, 400), (0, 255, 0), 3)
        cv2.rectangle(image, (50, int(vol_bar)), (85, 400), (0, 255, 0), cv2.FILLED)
        cv2.putText(image, f'{int(vol_per)} %', (40, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 3)
        
    def run_keyboard_mode(self, image, hand_landmarks):
        """Ø­Ø§Ù„Øª Ú©ÛŒØ¨ÙˆØ±Ø¯ Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
        image = self.draw_keyboard(image, self.buttonList)
        ix, iy = hand_landmarks.landmark[8].x * self.wCam, hand_landmarks.landmark[8].y * self.hCam
        
        for button in self.buttonList:
            x, y = button.pos
            w, h = button.size
            if x < ix < x + w and y < iy < y + h:
                cv2.rectangle(image, (x - 5, y - 5), (x + w + 5, y + h + 5), (175, 0, 175), cv2.FILLED)
                cv2.putText(image, button.text, (x + 20, y + 60), cv2.FONT_HERSHEY_PLAIN, 4, (255, 255, 255), 4)
                
                fingers = self.get_finger_states(hand_landmarks, "right")
                if fingers["finger_states"][1] == 1 and fingers["finger_states"][2] == 1:
                    mx, my = hand_landmarks.landmark[12].x * self.wCam, hand_landmarks.landmark[12].y * self.hCam
                    distance = math.hypot(mx - ix, my - iy)
                    
                    if distance < self.calibrated_thresholds["CLICK_DISTANCE"] * 1.2 and time.time() > self.click_cooldown:
                        if button.text == "Exit": 
                            self.state = "IDLE"
                        elif button.text == "<-": 
                            pyautogui.press('backspace')
                            self.final_text = self.final_text[:-1]
                        elif button.text == "Space": 
                            pyautogui.press('space')
                            self.final_text += " "
                        elif button.text == "Enter":
                            pyautogui.press('enter')
                            self.final_text += "\n"
                        else: 
                            pyautogui.press(button.text)
                            self.final_text += button.text
                        
                        self.click_cooldown = time.time() + self.CLICK_DELAY + 0.3
                        cv2.rectangle(image, (x - 5, y - 5), (x + w + 5, y + h + 5), (0, 255, 0), cv2.FILLED)
                        self.session_data["commands_executed"] += 1
                        print(f"âŒ¨ï¸ Ú©Ù„ÛŒØ¯ {button.text} ÙØ´Ø±Ø¯Ù‡ Ø´Ø¯")

        cv2.rectangle(image, (50, 550), (1200, 650), (50, 50, 50), cv2.FILLED)
        cv2.putText(image, self.final_text, (60, 620), cv2.FONT_HERSHEY_PLAIN, 4, (255, 255, 255), 4)
        return image
        
    def draw_keyboard(self, image, buttonList):
        """Ø±Ø³Ù… Ú©ÛŒØ¨ÙˆØ±Ø¯ Ù…Ø¬Ø§Ø²ÛŒ"""
        img_new = np.zeros_like(image, np.uint8)
        for button in buttonList:
            x, y = button.pos
            w, h = button.size
            color = button.color if hasattr(button, 'color') else (100, 0, 100)
            cv2.rectangle(img_new, (x, y), (x + w, y + h), color, cv2.FILLED)
            cv2.putText(img_new, button.text, (x + 20, y + 60), cv2.FONT_HERSHEY_PLAIN, 4, (255, 255, 255), 4)
        
        out = image.copy()
        alpha = 0.5
        mask = img_new.astype(bool)
        out[mask] = cv2.addWeighted(image, alpha, img_new, 1 - alpha, 0)[mask]
        return out
        
    def start_control(self):
        """Ø´Ø±ÙˆØ¹ Ú©Ù†ØªØ±Ù„"""
        self.state = "CALIBRATING"
        self.calibration_step = 0
        self.calibration_timer = time.time()
        self.start_button.configure(state="disabled")
        self.stop_button.configure(state="normal")
        self.update_status("Calibrating...")
        
        # Ø´Ø±ÙˆØ¹ Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ Ø¯Ø± thread Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
        self.control_thread = threading.Thread(target=self.main_loop)
        self.control_thread.daemon = True
        self.control_thread.start()
        
    def stop_control(self):
        """ØªÙˆÙ‚Ù Ú©Ù†ØªØ±Ù„"""
        self.state = "STOPPED"
        self.start_button.configure(state="normal")
        self.stop_button.configure(state="disabled")
        self.update_status("Stopped")
        
    def toggle_voice_control(self):
        """ØªØºÛŒÛŒØ± Ø­Ø§Ù„Øª Ú©Ù†ØªØ±Ù„ ØµÙˆØªÛŒ"""
        if not hasattr(self, 'voice_control_active'):
            self.voice_control_active = False
            
        if not self.voice_control_active:
            self.voice_control_active = True
            self.voice_button.configure(text="Stop Voice Control")
            if self.ai_controller:
                self.ai_controller.start_voice_control()
        else:
            self.voice_control_active = False
            self.voice_button.configure(text="Start Voice Control")
            if self.ai_controller:
                self.ai_controller.stop_voice_control()
            
    def update_status(self, status):
        """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ ÙˆØ¶Ø¹ÛŒØª"""
        self.status_label.configure(text=f"Status: {status}")
        
    def update_stats(self):
        """Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø±"""
        stats_text = f"""Statistics:
Commands: {self.session_data['commands_executed']}
Gestures: {self.session_data['gestures_detected']}
Errors: {self.session_data['errors']}
Uptime: {int(time.time() - self.session_data['start_time'])}s"""
        self.stats_label.configure(text=stats_text)
        
    def main_loop(self):
        """Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡"""
        print("ğŸ¯ Ø´Ø±ÙˆØ¹ Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ...")
        while self.state != "STOPPED":
            try:
                success, image = self.cap.read()
                if not success: 
                    print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ØªØµÙˆÛŒØ± Ø§Ø² Ø¯ÙˆØ±Ø¨ÛŒÙ†")
                    continue
                    
                image = cv2.flip(image, 1)
                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                results = self.hands.process(image_rgb)
                
                left_hand, right_hand = None, None
                
                if results.multi_hand_landmarks:
                    for i, hand_landmarks in enumerate(results.multi_hand_landmarks):
                        hand_type = results.multi_handedness[i].classification[0].label
                        if hand_type == "Left":
                            left_hand = hand_landmarks
                        else:
                            right_hand = hand_landmarks
                    
                    if left_hand:
                        self.mp_drawing.draw_landmarks(image, left_hand, self.mp_hands.HAND_CONNECTIONS)
                        self.previous_hand_landmarks['left'] = left_hand # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ø±Ø§ÛŒ Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ú˜Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
                    if right_hand:
                        self.mp_drawing.draw_landmarks(image, right_hand, self.mp_hands.HAND_CONNECTIONS)
                        self.previous_hand_landmarks['right'] = right_hand # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ø±Ø§ÛŒ Ø±Ø¯ÛŒØ§Ø¨ÛŒ Ú˜Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
                else:
                    self.previous_hand_landmarks = {'left': None, 'right': None} # Ø§Ú¯Ø± Ø¯Ø³ØªÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯ØŒ Ø±ÛŒØ³Øª Ú©Ù†

                # ØªØ´Ø®ÛŒØµ Ú˜Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ù‚Ø¨Ù„ Ø§Ø² Ú©Ù†ØªØ±Ù„ Ø­Ø§Ù„Øª Ø¹Ø§Ø¯ÛŒ
                self.detect_advanced_gestures(image, left_hand, right_hand)

                # Ø§Ø¬Ø±Ø§ÛŒ Ø­Ø§Ù„Øªâ€ŒÙ‡Ø§
                if self.state == "CALIBRATING":
                    active_hand = left_hand or right_hand
                    self.run_calibration(image, active_hand)
                
                elif self.state == "IDLE":
                    self.draw_text_with_bg(image, "IDLE", (10, 40), color=(255, 255, 0))
                    self.draw_text_with_bg(image, "Use Left Hand to Select Mode:", (10, 80), 0.7)
                    self.draw_text_with_bg(image, "1 Finger: Mouse | 2 Fingers: System | 3 Fingers: Keyboard", (10, 110), 0.7)
                    self.draw_text_with_bg(image, "Open Palm (5 Fingers): Back to IDLE", (10, 140), 0.7)

                # Ú©Ù†ØªØ±Ù„ Ø­Ø§Ù„Øªâ€ŒÙ‡Ø§ÛŒ Ù…Ø§ÙˆØ³ØŒ Ø³ÛŒØ³ØªÙ… Ùˆ Ú©ÛŒØ¨ÙˆØ±Ø¯ ÙÙ‚Ø· Ø§Ú¯Ø± Ú˜Ø³Øª Ù¾ÛŒØ´Ø±ÙØªÙ‡ ÙØ¹Ø§Ù„ Ù†Ø¨Ø§Ø´Ø¯
                elif right_hand and time.time() - self.last_state_change_time > 0.5: # ØªØ§Ø®ÛŒØ± Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªØ¯Ø§Ø®Ù„ Ø¨Ø§ Ú˜Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡
                    if self.state == "MOUSE_CONTROL":
                        self.run_mouse_control(image, right_hand)
                    elif self.state == "SYSTEM_CONTROL":
                        self.run_system_control(image, right_hand)
                    elif self.state == "KEYBOARD_MODE":
                        image = self.run_keyboard_mode(image, right_hand)
                elif self.state != "CALIBRATING" and self.state != "IDLE":
                     self.draw_text_with_bg(image, f"Show Right Hand to use {self.state}", (self.wCam//2 - 200, self.hCam//2), color=(0,0,255))

                # Ú©Ù†ØªØ±Ù„ ØªØºÛŒÛŒØ± Ø­Ø§Ù„Øª Ø¨Ø§ Ø¯Ø³Øª Ú†Ù¾
                if left_hand and time.time() - self.last_state_change_time > 1.0:
                    left_fingers_data = self.get_finger_states(left_hand, "Left")
                    left_fingers = left_fingers_data["finger_states"]
                    
                    if sum(left_fingers) == 5 and self.state != "IDLE" and self.state != "CALIBRATING":
                        self.state = "IDLE"
                        self.final_text = ""
                        self.last_state_change_time = time.time()
                        self.update_status("IDLE")
                        print("ğŸ”„ Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ø­Ø§Ù„Øª IDLE")
                    
                    elif self.state == "IDLE":
                        if sum(left_fingers) == 1 and left_fingers[1] == 1:
                            self.state = "MOUSE_CONTROL"
                            self.last_state_change_time = time.time()
                            self.update_status("Mouse Control")
                            print("ğŸ–±ï¸ ØªØºÛŒÛŒØ± Ø¨Ù‡ Ø­Ø§Ù„Øª Ú©Ù†ØªØ±Ù„ Ù…Ø§ÙˆØ³")
                        elif sum(left_fingers) == 2 and left_fingers[1] == 1 and left_fingers[2] == 1:
                            self.state = "SYSTEM_CONTROL"
                            self.last_state_change_time = time.time()
                            self.update_status("System Control")
                            print("ğŸ”Š ØªØºÛŒÛŒØ± Ø¨Ù‡ Ø­Ø§Ù„Øª Ú©Ù†ØªØ±Ù„ Ø³ÛŒØ³ØªÙ…")
                        elif sum(left_fingers) == 3 and left_fingers[1] == 1 and left_fingers[2] == 1 and left_fingers[3] == 1:
                            self.state = "KEYBOARD_MODE"
                            self.last_state_change_time = time.time()
                            self.update_status("Keyboard Mode")
                            print("âŒ¨ï¸ ØªØºÛŒÛŒØ± Ø¨Ù‡ Ø­Ø§Ù„Øª Ú©ÛŒØ¨ÙˆØ±Ø¯")

                # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø±
                self.update_stats()
                
                cv2.imshow("Advanced Hand Controller Pro v3.0 - Fixed", image)
                
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    print("ğŸ›‘ Ø®Ø±ÙˆØ¬ Ø§Ø² Ø¨Ø±Ù†Ø§Ù…Ù‡...")
                    break
                    
            except Exception as e:
                print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ: {e}")
                self.session_data["errors"] += 1
                time.sleep(0.1)
                
        self.cap.release()
        cv2.destroyAllWindows()
        print("âœ… Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø³ØªÙ‡ Ø´Ø¯")
        
    def run(self):
        """Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡"""
        print("ğŸš€ Ø´Ø±ÙˆØ¹ Ø¨Ø±Ù†Ø§Ù…Ù‡...")
        try:
            self.root.mainloop()
        except KeyboardInterrupt:
            print("ğŸ›‘ Ø¨Ø±Ù†Ø§Ù…Ù‡ ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø± Ù…ØªÙˆÙ‚Ù Ø´Ø¯")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡: {e}")
        finally:
            if hasattr(self, 'cap'):
                self.cap.release()
            cv2.destroyAllWindows()

def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ"""
    print("=" * 50)
    print("Hand Controller Pro v3.0 - Fixed Version")
    print("=" * 50)
    
    try:
        controller = FixedHandController()
        controller.run()
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ: {e}")
        input("Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ Enter Ø±Ø§ ÙØ´Ø§Ø± Ø¯Ù‡ÛŒØ¯...")

if __name__ == "__main__":
    main()
